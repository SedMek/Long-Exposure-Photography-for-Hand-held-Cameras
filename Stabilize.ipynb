{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Video Stabilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Input and Output Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input video\n",
    "input_video = 'Data/piano.mp4'\n",
    "cap = cv2.VideoCapture(input_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frame count\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Get fps\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Get width and height of video stream\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the codec for output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTHING_RADIUS = 100 # TODO: Try different values\n",
    "\n",
    "# Set up output video\n",
    "out = cv2.VideoWriter('{}_stabilized_{}.avi'.format(input_video.split('.')[0], SMOOTHING_RADIUS), fourcc, fps, (w, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the first frame and convert it to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read first frame\n",
    "_, prev = cap.read() \n",
    " \n",
    "# Convert frame to grayscale\n",
    "prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find motion between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-define transformation-store array\n",
    "transforms = np.zeros((n_frames-1, 3), np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [00:00<00:00, 79.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# for i in tqdm(range(n_frames-2)):\n",
    "for i in tqdm(range(57)):\n",
    "    # Detect feature points in previous frame\n",
    "    prev_pts = cv2.goodFeaturesToTrack(prev_gray,\n",
    "                                       maxCorners=200,\n",
    "                                       qualityLevel=0.01,\n",
    "                                       minDistance=30,\n",
    "                                       blockSize=3)\n",
    "    # Read next frame\n",
    "    success, curr = cap.read() \n",
    "    if not success: \n",
    "        print(\"Finished the whole video\")\n",
    "        break\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate optical flow (i.e. track feature points)\n",
    "    curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None) \n",
    " \n",
    "    # Sanity check\n",
    "    assert prev_pts.shape == curr_pts.shape \n",
    "    \n",
    "    # Filter only valid points (the ones that are not occulated or out of frame)\n",
    "    idx = np.where(status==1)[0]\n",
    "    prev_pts = prev_pts[idx]\n",
    "    curr_pts = curr_pts[idx]\n",
    "    \n",
    "    #Find transformation matrix\n",
    "    m = cv2.estimateAffinePartial2D(prev_pts, curr_pts)[0]\n",
    "    \n",
    "    # Extract traslation\n",
    "    dx = m[0,2]\n",
    "    dy = m[1,2]\n",
    "\n",
    "    # Extract rotation angle\n",
    "    da = np.arctan2(m[1,0], m[0,0])\n",
    "\n",
    "    # Store transformation\n",
    "    transforms[i] = [dx,dy,da]\n",
    "\n",
    "    # Move to next frame\n",
    "    prev_gray = curr_gray    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate smooth motion between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute trajectory using cumulative sum of transformations\n",
    "trajectory = np.cumsum(transforms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingAverage(curve, radius): \n",
    "    window_size = 2 * radius + 1\n",
    "    # Define the filter \n",
    "    f = np.ones(window_size)/window_size \n",
    "    # Add padding to the boundaries \n",
    "    curve_pad = np.lib.pad(curve, (radius, radius), 'edge') \n",
    "    # Apply convolution \n",
    "    curve_smoothed = np.convolve(curve_pad, f, mode='same') \n",
    "    # Remove padding \n",
    "    curve_smoothed = curve_smoothed[radius:-radius]\n",
    "    # return smoothed curve\n",
    "    return curve_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(trajectory): \n",
    "    smoothed_trajectory = np.copy(trajectory) \n",
    "    # Filter the x, y and angle curves\n",
    "    for i in range(3):\n",
    "        smoothed_trajectory[:,i] = movingAverage(trajectory[:,i], radius=SMOOTHING_RADIUS)\n",
    "\n",
    "    return smoothed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_trajectory = smooth(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference in smoothed_trajectory and trajectory\n",
    "difference = smoothed_trajectory - trajectory\n",
    "  \n",
    "# Calculate newer transformation array\n",
    "transforms_smooth = transforms + difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply smoothed camera motion to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixBorder(frame):\n",
    "    s = frame.shape\n",
    "    # Scale the image 10% without moving the center\n",
    "    T = cv2.getRotationMatrix2D((s[1]/2, s[0]/2), 0, 1.1)\n",
    "    frame = cv2.warpAffine(frame, T, (s[1], s[0]))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1284/1284 [00:04<00:00, 260.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reset stream to first frame \n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n",
    "max_up = 0\n",
    "# Write n_frames-1 transformed frames\n",
    "for i in tqdm(range(n_frames-2)):\n",
    "    # Read next frame\n",
    "    success, frame = cap.read() \n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Extract transformations from the new transformation array\n",
    "    dx = transforms_smooth[i,0]\n",
    "    dy = transforms_smooth[i,1]\n",
    "    da = transforms_smooth[i,2]\n",
    "\n",
    "    # Reconstruct transformation matrix accordingly to new values\n",
    "    m = np.zeros((2,3), np.float32)\n",
    "    m[0,0] = np.cos(da)\n",
    "    m[0,1] = -np.sin(da)\n",
    "    m[1,0] = np.sin(da)\n",
    "    m[1,1] = np.cos(da)\n",
    "    m[0,2] = dx\n",
    "    m[1,2] = dy\n",
    "\n",
    "    # Apply affine wrapping to the given frame\n",
    "    frame_stabilized = cv2.warpAffine(frame, m, (w,h))\n",
    "    \n",
    "    # Fix border artifacts\n",
    "    frame_stabilized = fixBorder(frame_stabilized) \n",
    "#     # Write the frame to the file\n",
    "#     frame_out = cv2.hconcat([frame, frame_stabilized])\n",
    "\n",
    "    out.write(frame_stabilized)\n",
    "    \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
